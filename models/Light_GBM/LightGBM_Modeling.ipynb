{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report"
      ],
      "metadata": {
        "id": "ZZGp4_b8qz2M"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Data_Processed_SRV.csv')"
      ],
      "metadata": {
        "id": "wuHlsWhjhevS"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.values[:, :-2]\n",
        "y = df.values[:, -2]\n",
        "y = y.astype(int)"
      ],
      "metadata": {
        "id": "CjbwjroorE6p"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = SelectKBest(score_func=chi2, k=15)\n",
        "fit = test.fit(X, y)\n",
        "np.set_printoptions(precision=3)\n",
        "features = fit.transform(X)"
      ],
      "metadata": {
        "id": "j6Hr8Uw5rJja"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_features_mask = fit.get_support()\n",
        "your_feature_labels = df.columns.tolist()\n",
        "\n",
        "selected_feature_indices = np.where(selected_features_mask)[0]\n",
        "selected_feature_labels = [your_feature_labels[i] for i in selected_feature_indices]\n"
      ],
      "metadata": {
        "id": "c36ZupR4rJ_x"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
        "\n",
        "lgb_clf = lgb.LGBMClassifier(random_state=0)\n",
        "\n",
        "lgb_clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = lgb_clf.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPwxAKrFqoAl",
        "outputId": "af650af1-57d2-45cb-fb67-ecdcfb511b1f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 553765, number of negative: 358152\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.319964 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6168\n",
            "[LightGBM] [Info] Number of data points in the train set: 911917, number of used features: 67\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.607254 -> initscore=0.435783\n",
            "[LightGBM] [Info] Start training from score 0.435783\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision_benign = precision_score(y_test, y_pred, pos_label=0)\n",
        "recall_benign = recall_score(y_test, y_pred, pos_label=0)\n",
        "f1_benign = f1_score(y_test, y_pred, pos_label=0)\n",
        "precision_malicious = precision_score(y_test, y_pred, pos_label=1)\n",
        "recall_malicious = recall_score(y_test, y_pred, pos_label=1)\n",
        "f1_malicious = f1_score(y_test, y_pred, pos_label=1)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"precision_benign:\", precision_benign)\n",
        "print(\"recall_benign:\", recall_benign)\n",
        "print(\"f1_benign:\", f1_benign)\n",
        "print(\"precision_malicious:\", precision_benign)\n",
        "print(\"recall_malicious:\", recall_benign)\n",
        "print(\"f1_malicious:\", f1_malicious)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqktkVwnraD3",
        "outputId": "c95d0ee5-a401-4e6e-e10c-1f4335c6f5bc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9996874722426005\n",
            "precision_benign: 0.9994315617006336\n",
            "recall_benign: 0.9997742191746456\n",
            "f1_benign: 0.9996028610724423\n",
            "precision_malicious: 0.9994315617006336\n",
            "recall_malicious: 0.9997742191746456\n",
            "f1_malicious: 0.9997423624011824\n"
          ]
        }
      ]
    }
  ]
}