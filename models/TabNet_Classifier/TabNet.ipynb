{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCbbvO9tqoEU",
        "outputId": "2f93b96b-3a22-4378-f1ad-3e927ed9783d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "#to ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/5G NIDD/Combined.csv'"
      ],
      "metadata": {
        "id": "N9qduJrxq0Tg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.applications import ResNet50\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Dropout\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "def data_preprocessing_binary(path):\n",
        "    df = pd.read_csv(path)\n",
        "    df_encoded = pd.get_dummies(df[['Proto','State']], columns=['Proto', 'State'])\n",
        "\n",
        "    select_features_df = df[[ 'AckDat', 'sHops', 'Seq','TcpRtt', 'dMeanPktSz', 'Offset', 'sTtl',  'Mean', 'SrcTCPBase', 'sMeanPktSz', 'DstLoss', 'Loss', 'dTtl', 'SrcBytes', 'TotBytes']]\n",
        "    select_features_df['sHops'].fillna(df['sHops'].mean(), inplace=True)\n",
        "    select_features_df['sTtl'].fillna(df['sTtl'].mean(), inplace=True)\n",
        "    select_features_df['SrcTCPBase'].fillna(df['SrcTCPBase'].mean(), inplace=True)\n",
        "    select_features_df['dTtl'].fillna(df['dTtl'].mean(), inplace=True)\n",
        "    df_merged = pd.concat([select_features_df, df_encoded], axis=1)\n",
        "\n",
        "    df_output_encoded = df['Label']\n",
        "    df_output_encoded_1 = df_output_encoded.replace(['Benign', 'Malicious'], [0, 1], inplace=False)\n",
        "\n",
        "    return df_merged, df_output_encoded_1\n",
        "\n",
        "# Load and preprocess data\n",
        "\n",
        "X, y = data_preprocessing_binary(path)\n"
      ],
      "metadata": {
        "id": "GognaqNrr9pr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_preprocessing_multiclass(path):\n",
        "  from sklearn.preprocessing import LabelEncoder\n",
        "  df = pd.read_csv(path)\n",
        "  df_encoded = pd.get_dummies(df[['Proto','State']], columns=['Proto', 'State'])\n",
        "  df_encoded_output = pd.get_dummies(df[['Proto','State']], columns=['Proto', 'State'])\n",
        "  select_features_df = df[[ 'AckDat', 'sHops', 'Seq','TcpRtt', 'dMeanPktSz', 'Offset', 'sTtl',  'Mean', 'SrcTCPBase', 'sMeanPktSz', 'DstLoss', 'Loss', 'dTtl', 'SrcBytes', 'TotBytes']]\n",
        "  select_features_df['sHops'].fillna(df['sHops'].mean(), inplace = True)\n",
        "  select_features_df['sTtl'].fillna(df['sTtl'].mean(), inplace = True)\n",
        "  select_features_df['SrcTCPBase'].fillna(df['SrcTCPBase'].mean(), inplace = True)\n",
        "  select_features_df['dTtl'].fillna(df['dTtl'].mean(), inplace = True)\n",
        "  df_merged = pd.concat([select_features_df, df_encoded], axis=1)\n",
        "\n",
        "  # df_output_encoded = df['Label']\n",
        "  # df_output_encoded_1 = df_output_encoded.replace(['Benign', 'Malicious'],\n",
        "  #                       [0, 1], inplace=False)\n",
        "\n",
        "  label_encoder = LabelEncoder()\n",
        "  df_output_encoded = label_encoder.fit_transform(df['Attack Type'])\n",
        "\n",
        "  # Convert output encoded array into DataFrame\n",
        "  df_output_encoded_1 = pd.DataFrame(df_output_encoded, columns=['Attack_Type_Encoded'])\n",
        "  print(df_output_encoded_1)\n",
        "  #returns input and output dataframe\n",
        "  return df_merged, df_output_encoded_1"
      ],
      "metadata": {
        "id": "jXmcWnGKMrEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-tabnet scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BjB1AOa2-Aj",
        "outputId": "fb0a8c29-ce6c-45e7-a552-43958892a083"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-tabnet\n",
            "  Downloading pytorch_tabnet-4.1.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.5/44.5 kB\u001b[0m \u001b[31m524.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.25.2)\n",
            "Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (2.2.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (4.66.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.3->pytorch-tabnet)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.3->pytorch-tabnet)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.3->pytorch-tabnet)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.3->pytorch-tabnet)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m669.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.3->pytorch-tabnet)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.3->pytorch-tabnet)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.3->pytorch-tabnet)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.3->pytorch-tabnet)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.3->pytorch-tabnet)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=1.3->pytorch-tabnet)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.3->pytorch-tabnet)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.3->pytorch-tabnet)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3->pytorch-tabnet) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3->pytorch-tabnet) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, pytorch-tabnet\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 pytorch-tabnet-4.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "\n",
        "# Assuming X is your DataFrame containing tabular data and y is your target variable\n",
        "\n",
        "# Convert DataFrame to numpy array\n",
        "X_array = X.values\n",
        "\n",
        "# Standardize your features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_array)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define TabNet model\n",
        "clf = TabNetClassifier()\n",
        "\n",
        "# Start the timer\n",
        "start_time = time.time()\n",
        "\n",
        "# End the timer\n",
        "end_time = time.time()\n",
        "\n",
        "# Train the model\n",
        "clf.fit(X_train, y_train, eval_set=[(X_test, y_test)], patience=10, max_epochs=100)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "9eXEuhto5Wy0",
        "outputId": "2aadf2e8-ef28-4ed5-b2b8-b9101d4d55ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 0.03825 | val_0_auc: 0.99917 |  0:01:23s\n",
            "epoch 1  | loss: 0.01886 | val_0_auc: 0.99995 |  0:02:25s\n",
            "epoch 2  | loss: 0.00846 | val_0_auc: 0.99999 |  0:03:30s\n",
            "epoch 3  | loss: 0.00712 | val_0_auc: 0.99996 |  0:04:32s\n",
            "epoch 4  | loss: 0.0089  | val_0_auc: 0.93302 |  0:05:35s\n",
            "epoch 5  | loss: 0.00734 | val_0_auc: 0.99286 |  0:06:36s\n",
            "epoch 6  | loss: 0.0063  | val_0_auc: 0.99471 |  0:07:39s\n",
            "epoch 7  | loss: 0.0074  | val_0_auc: 0.95962 |  0:08:44s\n",
            "epoch 8  | loss: 0.0053  | val_0_auc: 0.95715 |  0:09:43s\n",
            "epoch 9  | loss: 0.00545 | val_0_auc: 0.9911  |  0:10:44s\n",
            "epoch 10 | loss: 0.00518 | val_0_auc: 0.97825 |  0:11:44s\n",
            "epoch 11 | loss: 0.00592 | val_0_auc: 0.91619 |  0:12:45s\n",
            "epoch 12 | loss: 0.00521 | val_0_auc: 0.86581 |  0:13:46s\n",
            "\n",
            "Early stopping occurred at epoch 12 with best_epoch = 2 and best_val_0_auc = 0.99999\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'TabNetClassifier' object has no attribute 'score'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-d15d384d0185>\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Test accuracy: {test_acc}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'TabNetClassifier' object has no attribute 'score'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# Assuming X_test and y_test are your test data\n",
        "y_pred_proba = clf.predict_proba(X_test)[:, 1]\n",
        "y_pred = np.where(y_pred_proba > 0.5, 1, 0)  # Convert probabilities to binary predictions using a threshold (e.g., 0.5)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "\n",
        "print(f'Test accuracy: {accuracy}')\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'F1-score: {f1}')\n",
        "print(f'ROC AUC: {roc_auc}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQ_X3NgM59wG",
        "outputId": "5cf25bc3-c11b-49f0-96f8-c2e850ffb560"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.997923331880351\n",
            "Precision: 0.9992386287159337\n",
            "Recall: 0.9973334961732617\n",
            "F1-score: 0.9982851535042294\n",
            "ROC AUC: 0.9999916163915628\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = data_preprocessing_multiclass(path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xmyCxMrJHE9",
        "outputId": "1d2f4500-a60f-47db-ac98-4c9596d49e0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Attack_Type_Encoded\n",
            "0                          0\n",
            "1                          0\n",
            "2                          0\n",
            "3                          0\n",
            "4                          0\n",
            "...                      ...\n",
            "1215885                    0\n",
            "1215886                    0\n",
            "1215887                    0\n",
            "1215888                    0\n",
            "1215889                    0\n",
            "\n",
            "[1215890 rows x 1 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def data_preprocessing_multiclass(path):\n",
        "    from sklearn.preprocessing import LabelEncoder\n",
        "    import pandas as pd\n",
        "\n",
        "    df = pd.read_csv(path)\n",
        "    df_encoded = pd.get_dummies(df[['Proto','State']], columns=['Proto', 'State'])\n",
        "    select_features_df = df[[ 'AckDat', 'sHops', 'Seq','TcpRtt', 'dMeanPktSz', 'Offset', 'sTtl',  'Mean', 'SrcTCPBase', 'sMeanPktSz', 'DstLoss', 'Loss', 'dTtl', 'SrcBytes', 'TotBytes']]\n",
        "    select_features_df['sHops'].fillna(df['sHops'].mean(), inplace = True)\n",
        "    select_features_df['sTtl'].fillna(df['sTtl'].mean(), inplace = True)\n",
        "    select_features_df['SrcTCPBase'].fillna(df['SrcTCPBase'].mean(), inplace = True)\n",
        "    select_features_df['dTtl'].fillna(df['dTtl'].mean(), inplace = True)\n",
        "    df_merged = pd.concat([select_features_df, df_encoded], axis=1)\n",
        "\n",
        "    label_encoder = LabelEncoder()\n",
        "    df_output_encoded = label_encoder.fit_transform(df['Attack Type'])\n",
        "\n",
        "    # Returns input DataFrame and encoded labels\n",
        "    return df_merged, df_output_encoded\n"
      ],
      "metadata": {
        "id": "7-6DRv0zOF3L"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def data_preprocessing_multiclass_tabnet(path):\n",
        "    from sklearn.preprocessing import LabelEncoder\n",
        "    import pandas as pd\n",
        "\n",
        "    df = pd.read_csv(path)\n",
        "    df_encoded = pd.get_dummies(df[['Proto','State']], columns=['Proto', 'State'])\n",
        "    select_features_df = df[[ 'AckDat', 'sHops', 'Seq','TcpRtt', 'dMeanPktSz', 'Offset', 'sTtl',  'Mean', 'SrcTCPBase', 'sMeanPktSz', 'DstLoss', 'Loss', 'dTtl', 'SrcBytes', 'TotBytes']]\n",
        "    select_features_df['sHops'].fillna(df['sHops'].mean(), inplace = True)\n",
        "    select_features_df['sTtl'].fillna(df['sTtl'].mean(), inplace = True)\n",
        "    select_features_df['SrcTCPBase'].fillna(df['SrcTCPBase'].mean(), inplace = True)\n",
        "    select_features_df['dTtl'].fillna(df['dTtl'].mean(), inplace = True)\n",
        "    df_merged = pd.concat([select_features_df, df_encoded], axis=1)\n",
        "\n",
        "    label_encoder = LabelEncoder()\n",
        "    df_output_encoded = label_encoder.fit_transform(df['Attack Type'])\n",
        "\n",
        "    # Returns input DataFrame, encoded labels, and label encoder\n",
        "    return df_merged, df_output_encoded, label_encoder\n",
        "\n",
        "# Load data and preprocess\n",
        "X, y, label_encoder = data_preprocessing_multiclass_tabnet(path)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ThuuAlutNJD0"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize and train TabNet model for multiclass classification\n",
        "clf = TabNetClassifier()\n",
        "clf.fit(X_train.values, y_train, eval_set=[(X_test.values, y_test)], patience=10, max_epochs=100)\n",
        "\n"
      ],
      "metadata": {
        "id": "dPNt_NpvNPdQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51c35a6e-1351-4789-8a95-4743f283391d"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 0.11845 | val_0_accuracy: 0.99372 |  0:01:07s\n",
            "epoch 1  | loss: 0.03152 | val_0_accuracy: 0.9948  |  0:02:11s\n",
            "epoch 2  | loss: 0.02515 | val_0_accuracy: 0.99611 |  0:03:19s\n",
            "epoch 3  | loss: 0.02158 | val_0_accuracy: 0.99313 |  0:04:28s\n",
            "epoch 4  | loss: 0.02129 | val_0_accuracy: 0.99637 |  0:05:37s\n",
            "epoch 5  | loss: 0.01687 | val_0_accuracy: 0.99714 |  0:06:41s\n",
            "epoch 6  | loss: 0.01684 | val_0_accuracy: 0.99641 |  0:07:45s\n",
            "epoch 7  | loss: 0.0155  | val_0_accuracy: 0.99305 |  0:08:48s\n",
            "epoch 8  | loss: 0.0152  | val_0_accuracy: 0.99548 |  0:09:52s\n",
            "epoch 9  | loss: 0.01475 | val_0_accuracy: 0.99396 |  0:10:57s\n",
            "epoch 10 | loss: 0.01456 | val_0_accuracy: 0.9959  |  0:12:01s\n",
            "epoch 11 | loss: 0.01312 | val_0_accuracy: 0.99338 |  0:13:05s\n",
            "epoch 12 | loss: 0.01187 | val_0_accuracy: 0.98497 |  0:14:07s\n",
            "epoch 13 | loss: 0.01246 | val_0_accuracy: 0.99678 |  0:15:12s\n",
            "epoch 14 | loss: 0.01206 | val_0_accuracy: 0.99678 |  0:16:15s\n",
            "epoch 15 | loss: 0.01244 | val_0_accuracy: 0.98592 |  0:17:19s\n",
            "\n",
            "Early stopping occurred at epoch 15 with best_epoch = 5 and best_val_0_accuracy = 0.99714\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = clf.predict(X_test.values)\n",
        "\n",
        "# Compute evaluation metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'F1-score: {f1}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRDdpNPPOZrM",
        "outputId": "1602b234-3d1b-4e5a-a0ca-a113b640be50"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9971420112016712\n",
            "Precision: 0.9971565307232909\n",
            "Recall: 0.9971420112016712\n",
            "F1-score: 0.9971461437645467\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XBLL3LEPW-dp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}