{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "XsZA6nKH_LU1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "import joblib",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#mount google drive\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "path = \"/content/drive/MyDrive/\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXrm0A3__QC_",
        "outputId": "4e6b952c-f9ee-4193-8faa-39b89a304a69"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combinedDf = pd.read_csv('../../data_processed/updated_Combined.csv')\n",
        "\n",
        "combinedDf.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBrdRk63_SJM",
        "outputId": "9b11ca37-7d0a-48ad-a6d5-12bdf4914226"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1215890 entries, 0 to 1215889\n",
            "Data columns (total 24 columns):\n",
            " #   Column       Non-Null Count    Dtype  \n",
            "---  ------       --------------    -----  \n",
            " 0   Unnamed: 0   1215890 non-null  float64\n",
            " 1   Seq          1215890 non-null  float64\n",
            " 2   Dur          1215890 non-null  float64\n",
            " 3   RunTime      1215890 non-null  float64\n",
            " 4   Mean         1215890 non-null  float64\n",
            " 5   Sum          1215890 non-null  float64\n",
            " 6   Min          1215890 non-null  float64\n",
            " 7   Max          1215890 non-null  float64\n",
            " 8   TotPkts      1215890 non-null  float64\n",
            " 9   SrcPkts      1215890 non-null  float64\n",
            " 10  DstPkts      1215890 non-null  float64\n",
            " 11  TotBytes     1215890 non-null  float64\n",
            " 12  SrcBytes     1215890 non-null  float64\n",
            " 13  DstBytes     1215890 non-null  float64\n",
            " 14  Offset       1215890 non-null  float64\n",
            " 15  sMeanPktSz   1215890 non-null  float64\n",
            " 16  dMeanPktSz   1215890 non-null  float64\n",
            " 17  Load         1215890 non-null  float64\n",
            " 18  SrcLoad      1215890 non-null  float64\n",
            " 19  Rate         1215890 non-null  float64\n",
            " 20  SrcRate      1215890 non-null  float64\n",
            " 21  Label        1215890 non-null  object \n",
            " 22  Attack Type  1215890 non-null  object \n",
            " 23  Attack Tool  1215890 non-null  object \n",
            "dtypes: float64(21), object(3)\n",
            "memory usage: 222.6+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features = ['Seq', 'Dur', 'RunTime', 'Mean', 'Sum', 'Min', 'Max',\n",
        "            'TotPkts', 'SrcPkts', 'DstPkts', 'TotBytes', 'SrcBytes',\n",
        "            'DstBytes', 'Offset', 'sMeanPktSz', 'dMeanPktSz',\n",
        "            'Load', 'SrcLoad', 'Rate', 'SrcRate']\n",
        "target = 'Label'"
      ],
      "metadata": {
        "id": "JQBro7--_ZKE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(combinedDf[features], combinedDf[target], test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "X3g73LNP_bf0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a pipeline with StandardScaler and LogisticRegression\n",
        "logreg_model = make_pipeline(StandardScaler(), LogisticRegression(max_iter=1000))\n",
        "\n",
        "# Train the logistic regression model\n",
        "logreg_model.fit(X_train, y_train)\n",
        "\n",
        "joblib.dump(logreg_model, path + 'Models/logistic_model.pkl')",
        "# Predict on the test set\n",
        "y_pred = logreg_model.predict(X_test)"
      ],
      "metadata": {
        "id": "__uMHvex_esU"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision_benign = precision_score(y_test, y_pred, pos_label='Benign')\n",
        "recall_benign = recall_score(y_test, y_pred, pos_label='Benign')\n",
        "f1_benign = f1_score(y_test, y_pred, pos_label='Benign')\n",
        "precision_malicious = precision_score(y_test, y_pred, pos_label='Malicious')\n",
        "recall_malicious = recall_score(y_test, y_pred, pos_label='Malicious')\n",
        "f1_malicious = f1_score(y_test, y_pred, pos_label='Malicious')\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"precision_benign:\", precision_benign)\n",
        "print(\"recall_benign:\", recall_benign)\n",
        "print(\"f1_benign:\", f1_benign)\n",
        "print(\"precision_malicious:\", precision_benign)\n",
        "print(\"recall_malicious:\", recall_benign)\n",
        "print(\"f1_malicious:\", f1_malicious)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJbBJHKQBMV7",
        "outputId": "a61ec9df-d0df-485d-a8c6-a229910c24ad"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9257210767421395\n",
            "precision_benign: 0.9371871449622605\n",
            "recall_benign: 0.8697308808484874\n",
            "f1_benign: 0.902199866805997\n",
            "precision_malicious: 0.9371871449622605\n",
            "recall_malicious: 0.8697308808484874\n",
            "f1_malicious: 0.9401219241338845\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PcvCV282BPh6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
