{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpINtNEXSA8I",
        "outputId": "28dc90dd-d1c4-46eb-fea5-8539866b10ed"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/5G NIDD/updated_Combined.csv')"
      ],
      "metadata": {
        "id": "yB2mHcv9R2df"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print ('object_columns:{}', df.select_dtypes(include=[object]).columns)\n",
        "print('float_columns: {}', df.select_dtypes(include=[float]).columns)\n",
        "print('int_columns:{}',  df.select_dtypes(include=[int]).columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEoU0sStXdRL",
        "outputId": "a964cea7-3a20-4e30-adb7-1b313bfe4a95"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "object_columns:{} Index(['Proto', 'Cause', 'State', 'Label', 'Attack Type', 'Attack Tool'], dtype='object')\n",
            "float_columns: {} Index(['Dur', 'sTtl', 'dTtl', 'sHops', 'dHops', 'sMeanPktSz', 'dMeanPktSz',\n",
            "       'Load', 'SrcLoad', 'DstLoad', 'pLoss', 'Rate', 'SrcRate', 'DstRate',\n",
            "       'SrcWin', 'DstWin', 'SrcTCPBase', 'DstTCPBase', 'TcpRtt', 'SynAck',\n",
            "       'AckDat'],\n",
            "      dtype='object')\n",
            "int_columns:{} Index(['Unnamed: 0', 'Seq', 'TotPkts', 'SrcPkts', 'DstPkts', 'TotBytes',\n",
            "       'SrcBytes', 'DstBytes', 'Offset', 'Loss', 'SrcLoss', 'DstLoss'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uxaw8hn-YXOg",
        "outputId": "d2ddb06e-ec2a-4fa0-ddd6-cadaabded816"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1215890, 39)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Conv1D, MaxPooling1D, Input, concatenate\n",
        "from keras.models import Model\n",
        "\n",
        "# Assuming 'df' is your cleaned dataset loaded into a pandas DataFrame\n",
        "# Assuming 'Label' is the column containing the labels (Benign/Malicious)\n",
        "\n",
        "# Remove unnecessary columns\n",
        "df = df.drop(columns=['Unnamed: 0', 'Seq', 'Attack Type', 'Attack Tool', 'Cause'])\n",
        "\n",
        "# One-hot encode categorical columns 'Proto' and 'State'\n",
        "df = pd.get_dummies(df, columns=['Proto', 'State'])\n",
        "\n",
        "# Convert categorical labels to numerical labels\n",
        "label_encoder = LabelEncoder()\n",
        "df['Label'] = label_encoder.fit_transform(df['Label'])\n",
        "\n",
        "# Separate features and target variable\n",
        "X = df.drop(columns=['Label'])\n",
        "y = df['Label']\n",
        "\n",
        "# Normalize only the numeric columns\n",
        "numeric_cols = X.select_dtypes(include=[np.number]).columns\n",
        "scaler = StandardScaler()\n",
        "X[numeric_cols] = scaler.fit_transform(X[numeric_cols])\n",
        "\n",
        "# Reshape the data for CNN input\n",
        "X = X.values.reshape(-1, X.shape[1], 1)\n",
        "y = y.values\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the CNN model\n",
        "input_shape = (X_train.shape[1], 1)\n",
        "input1 = Input(shape=input_shape)\n",
        "conv1 = Conv1D(filters=64, kernel_size=3, activation='relu')(input1)\n",
        "pool1 = MaxPooling1D(pool_size=2)(conv1)\n",
        "flat1 = Flatten()(pool1)\n",
        "\n",
        "# Define additional input for one-hot encoded features\n",
        "input2 = Input(shape=(X_train.shape[1],))  # Shape matches the number of features after one-hot encoding\n",
        "dense1 = Dense(50, activation='relu')(input2)\n",
        "\n",
        "# Concatenate the output of the CNN layers and the dense layer\n",
        "concat = concatenate([flat1, dense1])\n",
        "\n",
        "# Add more layers as needed\n",
        "dense2 = Dense(10, activation='relu')(concat)\n",
        "\n",
        "# Output layer\n",
        "output = Dense(1, activation='sigmoid')(dense2)\n",
        "\n",
        "# Combine inputs and outputs into a model\n",
        "model = Model(inputs=[input1, input2], outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit([X_train, X_train[:, :, 0]], y_train, epochs=10, batch_size=64, validation_data=([X_test, X_test[:, :, 0]], y_test))\n",
        "\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate([X_test, X_test[:, :, 0]], y_test)\n",
        "print(\"Test Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOum8lGhVgx5",
        "outputId": "a43cee1c-a759-497f-a66e-bfb64db82ed1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "15199/15199 [==============================] - 55s 4ms/step - loss: 0.0624 - accuracy: 0.9705 - val_loss: 0.0540 - val_accuracy: 0.9749\n",
            "Epoch 2/10\n",
            "15199/15199 [==============================] - 53s 3ms/step - loss: 0.0522 - accuracy: 0.9739 - val_loss: 0.0509 - val_accuracy: 0.9719\n",
            "Epoch 3/10\n",
            "15199/15199 [==============================] - 59s 4ms/step - loss: 0.0486 - accuracy: 0.9746 - val_loss: 0.0478 - val_accuracy: 0.9742\n",
            "Epoch 4/10\n",
            "15199/15199 [==============================] - 58s 4ms/step - loss: 0.0471 - accuracy: 0.9751 - val_loss: 0.0458 - val_accuracy: 0.9759\n",
            "Epoch 5/10\n",
            "15199/15199 [==============================] - 59s 4ms/step - loss: 0.0456 - accuracy: 0.9759 - val_loss: 0.0480 - val_accuracy: 0.9733\n",
            "Epoch 6/10\n",
            "15199/15199 [==============================] - 53s 4ms/step - loss: 0.0452 - accuracy: 0.9764 - val_loss: 0.0446 - val_accuracy: 0.9761\n",
            "Epoch 7/10\n",
            "15199/15199 [==============================] - 57s 4ms/step - loss: 0.0450 - accuracy: 0.9771 - val_loss: 0.0449 - val_accuracy: 0.9805\n",
            "Epoch 8/10\n",
            "15199/15199 [==============================] - 52s 3ms/step - loss: 0.0432 - accuracy: 0.9779 - val_loss: 0.0458 - val_accuracy: 0.9768\n",
            "Epoch 9/10\n",
            "15199/15199 [==============================] - 53s 3ms/step - loss: 0.0429 - accuracy: 0.9787 - val_loss: 0.0451 - val_accuracy: 0.9775\n",
            "Epoch 10/10\n",
            "15199/15199 [==============================] - 51s 3ms/step - loss: 0.0414 - accuracy: 0.9796 - val_loss: 0.0427 - val_accuracy: 0.9812\n",
            "7600/7600 [==============================] - 10s 1ms/step - loss: 0.0427 - accuracy: 0.9812\n",
            "Test Accuracy: 0.9812359809875488\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Predict probabilities for test set\n",
        "y_pred_probs = model.predict([X_test, X_test[:, :, 0]])\n",
        "\n",
        "# Convert probabilities to binary predictions\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWpmxevXWx-6",
        "outputId": "209dbb13-dcc2-4d4e-ad07-be1d4291a089"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7600/7600 [==============================] - 15s 2ms/step\n",
            "Accuracy: 0.9812359670693895\n",
            "Precision: 0.9732086649393334\n",
            "Recall: 0.9964718015524073\n",
            "F1-score: 0.9847028572769544\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"X_train dtype:\", X_train.dtype)\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_train[:, :, 0] dtype:\", X_train[:, :, 0].dtype)\n",
        "print(\"X_train[:, :, 0] shape:\", X_train[:, :, 0].shape)\n",
        "\n",
        "print(\"X_test dtype:\", X_test.dtype)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"X_test[:, :, 0] dtype:\", X_test[:, :, 0].dtype)\n",
        "print(\"X_test[:, :, 0] shape:\", X_test[:, :, 0].shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ou_1ej_1Zt-g",
        "outputId": "b14fb614-d9f9-482d-8c21-cdac86e64375"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train dtype: object\n",
            "X_train shape: (972712, 51, 1)\n",
            "X_train[:, :, 0] dtype: object\n",
            "X_train[:, :, 0] shape: (972712, 51)\n",
            "X_test dtype: object\n",
            "X_test shape: (243178, 51, 1)\n",
            "X_test[:, :, 0] dtype: object\n",
            "X_test[:, :, 0] shape: (243178, 51)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace non-numeric values with NaN\n",
        "X_train = np.where(X_train == 'Start', np.nan, X_train)\n",
        "X_test = np.where(X_test == 'Start', np.nan, X_test)\n",
        "\n",
        "# Convert to numeric values\n",
        "X_train = np.array([[pd.to_numeric(cell, errors='coerce') for cell in row] for row in X_train])\n",
        "X_test = np.array([[pd.to_numeric(cell, errors='coerce') for cell in row] for row in X_test])\n",
        "\n",
        "# Fill NaN values with a specific value or strategy (for example, median)\n",
        "X_train = np.nan_to_num(X_train, nan=np.nanmedian(X_train))\n",
        "X_test = np.nan_to_num(X_test, nan=np.nanmedian(X_test))\n",
        "\n",
        "# Reshape the data for CNN input\n",
        "X_train = X_train.reshape(-1, X_train.shape[1], 1)\n",
        "X_test = X_test.reshape(-1, X_test.shape[1], 1)\n",
        "\n"
      ],
      "metadata": {
        "id": "ictLuByxaCyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(columns=['Cause'])"
      ],
      "metadata": {
        "id": "fxTfB3VtcB2_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}