{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpINtNEXSA8I",
        "outputId": "1d2ffddd-73a5-493d-be6b-c758b8e45b21"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/5G NIDD/updated_Combined.csv')"
      ],
      "metadata": {
        "id": "yB2mHcv9R2df"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print ('object_columns:{}', df.select_dtypes(include=[object]).columns)\n",
        "print('float_columns: {}', df.select_dtypes(include=[float]).columns)\n",
        "print('int_columns:{}',  df.select_dtypes(include=[int]).columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEoU0sStXdRL",
        "outputId": "6f25a9c0-05a4-49b5-9ffc-f8f248d8554a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "object_columns:{} Index(['Proto', 'Cause', 'State', 'Label', 'Attack Type', 'Attack Tool'], dtype='object')\n",
            "float_columns: {} Index(['Dur', 'sTtl', 'dTtl', 'sHops', 'dHops', 'sMeanPktSz', 'dMeanPktSz',\n",
            "       'Load', 'SrcLoad', 'DstLoad', 'pLoss', 'Rate', 'SrcRate', 'DstRate',\n",
            "       'SrcWin', 'DstWin', 'SrcTCPBase', 'DstTCPBase', 'TcpRtt', 'SynAck',\n",
            "       'AckDat'],\n",
            "      dtype='object')\n",
            "int_columns:{} Index(['Unnamed: 0', 'Seq', 'TotPkts', 'SrcPkts', 'DstPkts', 'TotBytes',\n",
            "       'SrcBytes', 'DstBytes', 'Offset', 'Loss', 'SrcLoss', 'DstLoss'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uxaw8hn-YXOg",
        "outputId": "ec4eadf6-37de-484e-f3c6-fbc0ed55adb1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1215890, 39)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Conv1D, MaxPooling1D, Input, concatenate\n",
        "from keras.models import Model\n",
        "\n",
        "# Assuming 'df' is your cleaned dataset loaded into a pandas DataFrame\n",
        "# Assuming 'Label' is the column containing the labels (Benign/Malicious)\n",
        "\n",
        "# Remove unnecessary columns\n",
        "df = df.drop(columns=['Unnamed: 0', 'Seq', 'Attack Type', 'Attack Tool', 'Cause'])\n",
        "\n",
        "# One-hot encode categorical columns 'Proto' and 'State'\n",
        "df = pd.get_dummies(df, columns=['Proto', 'State'])\n",
        "\n",
        "# Convert categorical labels to numerical labels\n",
        "label_encoder = LabelEncoder()\n",
        "df['Label'] = label_encoder.fit_transform(df['Label'])\n",
        "\n",
        "# Separate features and target variable\n",
        "X = df.drop(columns=['Label'])\n",
        "y = df['Label']\n",
        "\n",
        "# Normalize only the numeric columns\n",
        "numeric_cols = X.select_dtypes(include=[np.number]).columns\n",
        "scaler = StandardScaler()\n",
        "X[numeric_cols] = scaler.fit_transform(X[numeric_cols])\n",
        "\n",
        "# Reshape the data for CNN input\n",
        "X = X.values.reshape(-1, X.shape[1], 1)\n",
        "y = y.values\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the CNN model\n",
        "input_shape = (X_train.shape[1], 1)\n",
        "input1 = Input(shape=input_shape)\n",
        "conv1 = Conv1D(filters=64, kernel_size=3, activation='relu')(input1)\n",
        "pool1 = MaxPooling1D(pool_size=2)(conv1)\n",
        "flat1 = Flatten()(pool1)\n",
        "\n",
        "# Define additional input for one-hot encoded features\n",
        "input2 = Input(shape=(X_train.shape[1],))  # Shape matches the number of features after one-hot encoding\n",
        "dense1 = Dense(50, activation='relu')(input2)\n",
        "\n",
        "# Concatenate the output of the CNN layers and the dense layer\n",
        "concat = concatenate([flat1, dense1])\n",
        "\n",
        "# Add more layers as needed\n",
        "dense2 = Dense(10, activation='relu')(concat)\n",
        "\n",
        "# Output layer\n",
        "output = Dense(1, activation='sigmoid')(dense2)\n",
        "\n",
        "# Combine inputs and outputs into a model\n",
        "model = Model(inputs=[input1, input2], outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit([X_train, X_train[:, :, 0]], y_train, epochs=10, batch_size=64, validation_data=([X_test, X_test[:, :, 0]], y_test))\n",
        "\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate([X_test, X_test[:, :, 0]], y_test)\n",
        "print(\"Test Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOum8lGhVgx5",
        "outputId": "bca68540-4ed2-4590-b37d-8cf1775a44a0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "15199/15199 [==============================] - 64s 4ms/step - loss: 0.0619 - accuracy: 0.9708 - val_loss: 0.0527 - val_accuracy: 0.9744\n",
            "Epoch 2/10\n",
            "15199/15199 [==============================] - 63s 4ms/step - loss: 0.0509 - accuracy: 0.9739 - val_loss: 0.0487 - val_accuracy: 0.9742\n",
            "Epoch 3/10\n",
            "15199/15199 [==============================] - 57s 4ms/step - loss: 0.0479 - accuracy: 0.9750 - val_loss: 0.0478 - val_accuracy: 0.9753\n",
            "Epoch 4/10\n",
            "15199/15199 [==============================] - 64s 4ms/step - loss: 0.0462 - accuracy: 0.9753 - val_loss: 0.0451 - val_accuracy: 0.9748\n",
            "Epoch 5/10\n",
            "15199/15199 [==============================] - 63s 4ms/step - loss: 0.0458 - accuracy: 0.9755 - val_loss: 0.0447 - val_accuracy: 0.9756\n",
            "Epoch 6/10\n",
            "15193/15199 [============================>.] - ETA: 0s - loss: 0.0451 - accuracy: 0.9757Epoch 7/10\n",
            "15199/15199 [==============================] - 62s 4ms/step - loss: 0.0447 - accuracy: 0.9760 - val_loss: 0.0480 - val_accuracy: 0.9749\n",
            "Epoch 8/10\n",
            "15199/15199 [==============================] - 64s 4ms/step - loss: 0.0443 - accuracy: 0.9763 - val_loss: 0.0436 - val_accuracy: 0.9765\n",
            "Epoch 9/10\n",
            "15199/15199 [==============================] - 63s 4ms/step - loss: 0.0438 - accuracy: 0.9767 - val_loss: 0.0439 - val_accuracy: 0.9790\n",
            "Epoch 10/10\n",
            "15199/15199 [==============================] - 64s 4ms/step - loss: 0.0435 - accuracy: 0.9771 - val_loss: 0.0424 - val_accuracy: 0.9763\n",
            "7600/7600 [==============================] - 11s 1ms/step - loss: 0.0424 - accuracy: 0.9763\n",
            "Test Accuracy: 0.9762684106826782\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"X_train dtype:\", X_train.dtype)\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_train[:, :, 0] dtype:\", X_train[:, :, 0].dtype)\n",
        "print(\"X_train[:, :, 0] shape:\", X_train[:, :, 0].shape)\n",
        "\n",
        "print(\"X_test dtype:\", X_test.dtype)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"X_test[:, :, 0] dtype:\", X_test[:, :, 0].dtype)\n",
        "print(\"X_test[:, :, 0] shape:\", X_test[:, :, 0].shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ou_1ej_1Zt-g",
        "outputId": "b14fb614-d9f9-482d-8c21-cdac86e64375"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train dtype: object\n",
            "X_train shape: (972712, 51, 1)\n",
            "X_train[:, :, 0] dtype: object\n",
            "X_train[:, :, 0] shape: (972712, 51)\n",
            "X_test dtype: object\n",
            "X_test shape: (243178, 51, 1)\n",
            "X_test[:, :, 0] dtype: object\n",
            "X_test[:, :, 0] shape: (243178, 51)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace non-numeric values with NaN\n",
        "X_train = np.where(X_train == 'Start', np.nan, X_train)\n",
        "X_test = np.where(X_test == 'Start', np.nan, X_test)\n",
        "\n",
        "# Convert to numeric values\n",
        "X_train = np.array([[pd.to_numeric(cell, errors='coerce') for cell in row] for row in X_train])\n",
        "X_test = np.array([[pd.to_numeric(cell, errors='coerce') for cell in row] for row in X_test])\n",
        "\n",
        "# Fill NaN values with a specific value or strategy (for example, median)\n",
        "X_train = np.nan_to_num(X_train, nan=np.nanmedian(X_train))\n",
        "X_test = np.nan_to_num(X_test, nan=np.nanmedian(X_test))\n",
        "\n",
        "# Reshape the data for CNN input\n",
        "X_train = X_train.reshape(-1, X_train.shape[1], 1)\n",
        "X_test = X_test.reshape(-1, X_test.shape[1], 1)\n",
        "\n"
      ],
      "metadata": {
        "id": "ictLuByxaCyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(columns=['Cause'])"
      ],
      "metadata": {
        "id": "fxTfB3VtcB2_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}